{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryCqBvfYWUhG",
        "outputId": "e56f3f61-79a7-4c3e-c64b-4c8eabd23108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INDIAN PINES BASELINE**"
      ],
      "metadata": {
        "id": "S6JwDWMieuFF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Nszu-rHVHXk",
        "outputId": "0cbd5780-4398-4654-dfbe-294494dd95bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [18:24:17] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training AdaBoost...\n",
            "Training CatBoost...\n",
            "Training Random Forest...\n",
            "Training PCA+SVM...\n",
            "\n",
            "Class-wise Accuracy Table:\n",
            "    XGBoost  AdaBoost  CatBoost  Random Forest  PCA+SVM\n",
            "0     90.67     85.34     89.79          90.95    87.42\n",
            "1     55.56      0.00     33.33          66.67    55.56\n",
            "2     81.05     32.63     80.35          76.84    73.33\n",
            "3     76.51      0.00     66.87          63.86    54.82\n",
            "4     46.81      4.26     63.83          57.45    53.19\n",
            "5     74.23      0.00     75.26          69.07    52.58\n",
            "6     78.08      0.00     76.03          69.18    72.60\n",
            "7     33.33      0.00     50.00          50.00    50.00\n",
            "8     95.83     12.50     94.79          96.88    94.79\n",
            "9     25.00      0.00      0.00           0.00    25.00\n",
            "10    79.90      0.00     76.29          80.41    61.86\n",
            "11    85.34     90.43     86.97          85.34    77.39\n",
            "12    62.18      0.00     58.82          65.55    29.41\n",
            "13    82.93      0.00     75.61          70.73    82.93\n",
            "14    69.96      9.09     62.06          54.15    49.01\n",
            "15    25.97      0.00      9.09           0.00     0.00\n",
            "16    78.95      0.00     73.68          52.63    78.95\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "file_path = \"/content/drive/MyDrive/IndianPines.csv\"  # Change this to your actual file path\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Extract features and labels\n",
        "X = data.iloc[:, :-1].values  # First 204 columns (spectral bands)\n",
        "y = data.iloc[:, -1].values   # Last column (class labels)\n",
        "\n",
        "# Split into train-test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize classifiers\n",
        "models = {\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
        "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100),\n",
        "    \"CatBoost\": CatBoostClassifier(verbose=0),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
        "    \"PCA+SVM\": SVC(kernel='linear')\n",
        "}\n",
        "\n",
        "# Apply PCA for SVM\n",
        "pca = PCA(n_components=50)  # Reduce to 50 components (tune this if needed)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# Train models and collect class-wise accuracy\n",
        "results = {class_label: {} for class_label in np.unique(y)}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Training {model_name}...\")\n",
        "    if model_name == \"PCA+SVM\":\n",
        "        model.fit(X_train_pca, y_train)\n",
        "        y_pred = model.predict(X_test_pca)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    # Compute class-wise accuracy\n",
        "    for class_label in np.unique(y):\n",
        "        mask = (y_test == class_label)\n",
        "        acc = accuracy_score(y_test[mask], y_pred[mask])\n",
        "        results[class_label][model_name] = round(acc * 100, 2)\n",
        "\n",
        "# Convert results to DataFrame and display\n",
        "results_df = pd.DataFrame(results).T  # Transpose to show class-wise results\n",
        "print(\"\\nClass-wise Accuracy Table:\")\n",
        "print(results_df)\n",
        "\n",
        "# Save results to CSV\n",
        "results_df.to_csv(\"classwise_accuracy_results.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INDIAN PINES FEW SHOTS**"
      ],
      "metadata": {
        "id": "OHEoPdX2e1mC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the CSV files\n",
        "csv_files = ['/content/drive/MyDrive/Patch_29_IP_CSV/patch_0.csv', '/content/drive/MyDrive/Patch_29_IP_CSV/patch_1.csv', '/content/drive/MyDrive/Patch_29_IP_CSV/patch_2.csv', '/content/drive/MyDrive/Patch_29_IP_CSV/patch_3.csv', '/content/drive/MyDrive/Patch_29_IP_CSV/patch_4.csv', '/content/drive/MyDrive/Patch_29_IP_CSV/patch_5.csv', '/content/drive/MyDrive/Patch_29_IP_CSV/patch_6.csv', '/content/drive/MyDrive/Patch_29_IP_CSV/patch_7.csv', '/content/drive/MyDrive/Patch_29_IP_CSV/patch_8.csv', '/content/drive/MyDrive/Patch_29_IP_CSV/patch_9.csv', '/content/drive/MyDrive/Patch_29_IP_CSV/patch_10.csv', '/content/drive/MyDrive/Patch_29_IP_CSV/patch_11.csv', '/content/drive/MyDrive/Patch_29_IP_CSV/patch_12.csv', '/content/drive/MyDrive/Patch_29_IP_CSV/patch_13.csv','/content/drive/MyDrive/Patch_29_IP_CSV/patch_14.csv','/content/drive/MyDrive/Patch_29_IP_CSV/patch_15.csv', '/content/drive/MyDrive/Patch_29_IP_CSV/patch_16.csv', '/content/drive/MyDrive/Patch_29_IP_CSV/patch_17.csv', '/content/drive/MyDrive/Patch_29_IP_CSV/patch_18.csv', '/content/drive/MyDrive/Patch_29_IP_CSV/patch_19.csv', '/content/drive/MyDrive/Patch_29_IP_CSV/patch_20.csv', '/content/drive/MyDrive/Patch_29_IP_CSV/patch_21.csv', '/content/drive/MyDrive/Patch_29_IP_CSV/patch_22.csv', '/content/drive/MyDrive/Patch_29_IP_CSV/patch_23.csv', '/content/drive/MyDrive/Patch_29_IP_CSV/patch_24.csv']\n",
        "dataframes = [pd.read_csv(file) for file in csv_files]\n",
        "\n",
        "# Concatenate all CSV data into a single dataframe\n",
        "data = pd.concat(dataframes)\n",
        "\n",
        "# Extract features and labels\n",
        "X = data.iloc[:, :-1].values  # First 204 columns (spectral bands)\n",
        "y = data.iloc[:, -1].values   # Last column (class labels)\n",
        "\n",
        "# Split into train-test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize classifiers\n",
        "models = {\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
        "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100),\n",
        "    \"CatBoost\": CatBoostClassifier(verbose=0),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
        "    \"PCA+SVM\": SVC(kernel='linear')\n",
        "}\n",
        "\n",
        "# Apply PCA for SVM\n",
        "pca = PCA(n_components=50)  # Reduce to 50 components (tune this if needed)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# Train models and collect class-wise accuracy\n",
        "results = {class_label: {} for class_label in np.unique(y)}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Training {model_name}...\")\n",
        "    if model_name == \"PCA+SVM\":\n",
        "        model.fit(X_train_pca, y_train)\n",
        "        y_pred = model.predict(X_test_pca)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    # Compute class-wise accuracy\n",
        "    for class_label in np.unique(y):\n",
        "        mask = (y_test == class_label)\n",
        "        acc = accuracy_score(y_test[mask], y_pred[mask])\n",
        "        results[class_label][model_name] = round(acc * 100, 2)\n",
        "\n",
        "# Convert results to DataFrame and display\n",
        "results_df = pd.DataFrame(results).T  # Transpose to show class-wise results\n",
        "print(\"\\nClass-wise Accuracy Table:\")\n",
        "print(results_df)\n",
        "\n",
        "# Save results to CSV\n",
        "results_df.to_csv(\"classwise_accuracy_results_IPFS.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfYQOAmNef6H",
        "outputId": "490d7fbd-9fae-4517-feda-c9c461958142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [19:03:54] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training AdaBoost...\n",
            "Training CatBoost...\n",
            "Training Random Forest...\n",
            "Training PCA+SVM...\n",
            "\n",
            "Class-wise Accuracy Table:\n",
            "    XGBoost  AdaBoost  CatBoost  Random Forest  PCA+SVM\n",
            "0     90.02     69.79     89.70          90.30    87.19\n",
            "1     55.56      0.00     33.33          55.56    55.56\n",
            "2     80.35     31.93     80.35          77.89    76.49\n",
            "3     81.33      0.00     75.30          62.65    53.61\n",
            "4     53.19      0.00     57.45          57.45    57.45\n",
            "5     75.26      0.00     73.20          67.01    45.36\n",
            "6     82.88      2.05     78.77          74.66    76.03\n",
            "7     50.00      0.00     33.33          33.33    50.00\n",
            "8     95.83      3.12     95.83          96.88    93.75\n",
            "9     25.00      0.00      0.00           0.00    50.00\n",
            "10    77.84      0.00     77.32          81.96    61.34\n",
            "11    87.98     76.17     86.97          88.59    80.04\n",
            "12    64.71      0.00     58.82          61.34    26.05\n",
            "13    92.68      0.00     97.56          87.80    90.24\n",
            "14    75.10     90.12     69.96          58.10    51.78\n",
            "15    23.38      0.00      6.49           1.30     0.00\n",
            "16    68.42      0.00     68.42          52.63    57.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SALINAS BASELINE**"
      ],
      "metadata": {
        "id": "3rDEUBebf3In"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "file_path = \"/content/drive/MyDrive/Salinas_Reduced.csv\"  # Change this to your actual file path\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Extract features and labels\n",
        "X = data.iloc[:, :-1].values  # First 204 columns (spectral bands)\n",
        "y = data.iloc[:, -1].values   # Last column (class labels)\n",
        "\n",
        "# Split into train-test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize classifiers\n",
        "models = {\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
        "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100),\n",
        "    \"CatBoost\": CatBoostClassifier(verbose=0),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
        "    \"PCA+SVM\": SVC(kernel='linear')\n",
        "}\n",
        "\n",
        "# Apply PCA for SVM\n",
        "pca = PCA(n_components=50)  # Reduce to 50 components (tune this if needed)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# Train models and collect class-wise accuracy\n",
        "results = {class_label: {} for class_label in np.unique(y)}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Training {model_name}...\")\n",
        "    if model_name == \"PCA+SVM\":\n",
        "        model.fit(X_train_pca, y_train)\n",
        "        y_pred = model.predict(X_test_pca)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    # Compute class-wise accuracy\n",
        "    for class_label in np.unique(y):\n",
        "        mask = (y_test == class_label)\n",
        "        acc = accuracy_score(y_test[mask], y_pred[mask])\n",
        "        results[class_label][model_name] = round(acc * 100, 2)\n",
        "\n",
        "# Convert results to DataFrame and display\n",
        "results_df = pd.DataFrame(results).T  # Transpose to show class-wise results\n",
        "print(\"\\nClass-wise Accuracy Table:\")\n",
        "print(results_df)\n",
        "\n",
        "# Save results to CSV\n",
        "results_df.to_csv(\"classwise_accuracy_results_Sal.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8RZKRjCgGPc",
        "outputId": "16452800-b56c-4067-ace6-9fcda819ce76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [19:17:40] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training AdaBoost...\n",
            "Training CatBoost...\n",
            "Training Random Forest...\n",
            "Training PCA+SVM...\n",
            "\n",
            "Class-wise Accuracy Table:\n",
            "    XGBoost  AdaBoost  CatBoost  Random Forest  PCA+SVM\n",
            "0     93.77     94.16     92.32          93.73    92.32\n",
            "1     93.75      1.25     96.25          97.50   100.00\n",
            "2     97.99     13.42     97.32          97.99    99.33\n",
            "3     83.54      0.00     77.22          82.28    16.46\n",
            "4     85.71      0.00     87.50          85.71    76.79\n",
            "5     92.52      0.00     93.46          94.39    89.72\n",
            "6     96.84      2.53     98.10          93.04    98.10\n",
            "7     99.30     25.87     99.30          97.20    97.90\n",
            "8     89.14      0.22     86.25          88.47    90.02\n",
            "9     93.15      0.00     92.34          88.71    85.48\n",
            "10    89.31      0.00     90.08          90.84    78.63\n",
            "11    79.07      0.00     76.74          72.09    83.72\n",
            "12    96.10      0.00     92.21          96.10    40.26\n",
            "13    86.11      0.00     88.89          91.67    75.00\n",
            "14    83.72      0.00     90.70          83.72    81.40\n",
            "15    71.13      0.00     68.04          65.29    56.36\n",
            "16    97.22      0.00     95.83          95.83    97.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SALINAS FEW SHOTS**"
      ],
      "metadata": {
        "id": "rTkX8hsOgmqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the CSV files\n",
        "csv_files = ['/content/drive/MyDrive/Patch_29_Sal_CSV/patch_0.csv', '/content/drive/MyDrive/Patch_29_Sal_CSV/patch_1.csv', '/content/drive/MyDrive/Patch_29_Sal_CSV/patch_2.csv', '/content/drive/MyDrive/Patch_29_Sal_CSV/patch_3.csv', '/content/drive/MyDrive/Patch_29_Sal_CSV/patch_4.csv', '/content/drive/MyDrive/Patch_29_Sal_CSV/patch_5.csv', '/content/drive/MyDrive/Patch_29_Sal_CSV/patch_6.csv', '/content/drive/MyDrive/Patch_29_Sal_CSV/patch_7.csv', '/content/drive/MyDrive/Patch_29_Sal_CSV/patch_8.csv', '/content/drive/MyDrive/Patch_29_Sal_CSV/patch_9.csv', '/content/drive/MyDrive/Patch_29_Sal_CSV/patch_10.csv', '/content/drive/MyDrive/Patch_29_Sal_CSV/patch_11.csv', '/content/drive/MyDrive/Patch_29_Sal_CSV/patch_12.csv', '/content/drive/MyDrive/Patch_29_Sal_CSV/patch_13.csv','/content/drive/MyDrive/Patch_29_Sal_CSV/patch_14.csv','/content/drive/MyDrive/Patch_29_Sal_CSV/patch_15.csv', '/content/drive/MyDrive/Patch_29_Sal_CSV/patch_16.csv', '/content/drive/MyDrive/Patch_29_Sal_CSV/patch_17.csv', '/content/drive/MyDrive/Patch_29_Sal_CSV/patch_18.csv', '/content/drive/MyDrive/Patch_29_Sal_CSV/patch_19.csv', '/content/drive/MyDrive/Patch_29_Sal_CSV/patch_20.csv', '/content/drive/MyDrive/Patch_29_Sal_CSV/patch_21.csv', '/content/drive/MyDrive/Patch_29_Sal_CSV/patch_22.csv', '/content/drive/MyDrive/Patch_29_Sal_CSV/patch_23.csv', '/content/drive/MyDrive/Patch_29_Sal_CSV/patch_24.csv']\n",
        "dataframes = [pd.read_csv(file) for file in csv_files]\n",
        "\n",
        "# Concatenate all CSV data into a single dataframe\n",
        "data = pd.concat(dataframes)\n",
        "\n",
        "# Extract features and labels\n",
        "X = data.iloc[:, :-1].values  # First 204 columns (spectral bands)\n",
        "y = data.iloc[:, -1].values   # Last column (class labels)\n",
        "\n",
        "# Split into train-test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize classifiers\n",
        "models = {\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
        "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100),\n",
        "    \"CatBoost\": CatBoostClassifier(verbose=0),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
        "    \"PCA+SVM\": SVC(kernel='linear')\n",
        "}\n",
        "\n",
        "# Apply PCA for SVM\n",
        "pca = PCA(n_components=50)  # Reduce to 50 components (tune this if needed)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# Train models and collect class-wise accuracy\n",
        "results = {class_label: {} for class_label in np.unique(y)}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Training {model_name}...\")\n",
        "    if model_name == \"PCA+SVM\":\n",
        "        model.fit(X_train_pca, y_train)\n",
        "        y_pred = model.predict(X_test_pca)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    # Compute class-wise accuracy\n",
        "    for class_label in np.unique(y):\n",
        "        mask = (y_test == class_label)\n",
        "        acc = accuracy_score(y_test[mask], y_pred[mask])\n",
        "        results[class_label][model_name] = round(acc * 100, 2)\n",
        "\n",
        "# Convert results to DataFrame and display\n",
        "results_df = pd.DataFrame(results).T  # Transpose to show class-wise results\n",
        "print(\"\\nClass-wise Accuracy Table:\")\n",
        "print(results_df)\n",
        "\n",
        "# Save results to CSV\n",
        "results_df.to_csv(\"classwise_accuracy_results_SalFS.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY449hJAgpVv",
        "outputId": "f6bc2906-2e93-4044-d92d-a6563863d3c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [19:31:21] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training AdaBoost...\n",
            "Training CatBoost...\n",
            "Training Random Forest...\n",
            "Training PCA+SVM...\n",
            "\n",
            "Class-wise Accuracy Table:\n",
            "    XGBoost  AdaBoost  CatBoost  Random Forest  PCA+SVM\n",
            "0     93.37     98.51     91.97          93.07    92.37\n",
            "1     92.50      0.00     93.75          93.75   100.00\n",
            "2     96.64      0.00     97.99          97.99    98.66\n",
            "3     86.08      0.00     74.68          79.75    22.78\n",
            "4     85.71     39.29     87.50          87.50    83.93\n",
            "5     95.33      0.00     94.39          95.33    89.72\n",
            "6     98.73      0.00     98.73          98.73    98.73\n",
            "7     95.80      0.00     97.90          95.80    99.30\n",
            "8     92.24      0.44     93.35          94.01    94.68\n",
            "9     93.55      0.00     91.13          91.13    85.48\n",
            "10    87.02      0.00     83.97          87.79    78.63\n",
            "11    76.19      0.00     83.33          69.05    85.71\n",
            "12    89.61      0.00     90.91          93.51    42.86\n",
            "13    83.78      0.00     86.49          86.49    72.97\n",
            "14    79.07      0.00     83.72          74.42    83.72\n",
            "15    46.40      0.00     48.00          41.60    40.00\n"
          ]
        }
      ]
    }
  ]
}